{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n",
      "sys.version_info(major=3, minor=9, micro=13, releaselevel='final', serial=0)\n",
      "matplotlib 3.5.2\n",
      "numpy 1.23.1\n",
      "pandas 1.4.4\n",
      "sklearn 1.1.2\n",
      "tensorflow 2.10.0\n",
      "keras.api._v2.keras 2.10.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%matplotlib inline\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for module in mpl, np, pd, sklearn, tf, keras:\n",
    "    print(module.__name__, module.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.environ['COMPUTERNAME'] == 'DESKTOP-EQAO3M5':\n",
    "  computer_flag = 'home'\n",
    "else:\n",
    "  computer_flag = 'office'\n",
    "\n",
    "if computer_flag == 'home':\n",
    "  file_dir = \"F:/github/pythonScript/seafog/data/collection/\"\n",
    "else:\n",
    "  file_dir = \"H:/github/python/seafog/data/collection/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_vis(x):\n",
    "    if(x <= 1000.0):\n",
    "      y = x/1000.0\n",
    "    elif(x > 1000.0 and x <= 10000.0):\n",
    "      y = (x-1000.0)/9000.0 + 1.0\n",
    "    elif( x > 10000.0  and x <= 30000.0):\n",
    "      y = (x-10000.0)/20000 + 2.0\n",
    "    else:\n",
    "      y = 3.0\n",
    "    return y\n",
    "\n",
    "def reverse_linear_vis(x):\n",
    "    if(x<0):\n",
    "      y = 1\n",
    "    elif(x <= 1.0):\n",
    "      y = x*1000.0\n",
    "    elif(x <= 2.0):\n",
    "      y = (x - 1.0)*9000.0 + 1000.0\n",
    "    elif(x <= 3.0):\n",
    "      y = (x-2.0)*20000 + 10000.0\n",
    "    else:\n",
    "      y = 30000.0\n",
    "    return y\n",
    "\n",
    "def setDataset(df, x_columns):\n",
    "    df['t_td'] =  df['t2mm'] - df['t2md']\n",
    "    df['td_sst'] =  df['t2md'] - df['sstk']\n",
    "    df['t_sst'] =  df['t2mm'] - df['sstk']\n",
    "    df['delta_theta'] = df['theta925'] - df['theta1000']\n",
    "    df['delta_theta_e'] = df['theta_e925'] - df['theta_e1000']\n",
    "    df_x = df.loc[:, x_columns]\n",
    "    df_y = df['station_vis_linear']\n",
    "    _x = df_x.to_numpy()\n",
    "    _y = df_y.to_numpy()\n",
    "    return (_x, _y)\n",
    "\n",
    "def getScore(x,y, model):\n",
    "    predictions = model(x).numpy()\n",
    "    y_p = predictions[:,0]\n",
    "    df_s = pd.DataFrame({'prediction':y_p, 'y':y})\n",
    "    df_s_fog = df_s.loc[df_s['y']<=1.0]\n",
    "    df_s_mist = df_s.loc[(df_s['y']>1.0) & (df_s['y']<=2.0)]\n",
    "    df_s_clear = df_s.loc[df_s['y']>2.0]\n",
    "    print('* 实况为雾时:', end=' ')\n",
    "    getLevelRatio(df_s_fog)\n",
    "    # print('-------------')\n",
    "    print('* 实况为轻雾时:', end=' ')\n",
    "    # print('-------------')\n",
    "    getLevelRatio(df_s_mist)\n",
    "    print('* 实况为无雾时:', end=' ')\n",
    "    getLevelRatio(df_s_clear)\n",
    "    print('* TS评分:', end=' ')\n",
    "    TS_fog = get_fog_TSscore(df_s, threshold=1.0)\n",
    "    TS_fog_mist = get_fog_TSscore(df_s, threshold=2.0)\n",
    "    print(f'雾: {TS_fog}, 轻雾及雾: {TS_fog_mist}')\n",
    "\n",
    "def getLevelRatio(df):\n",
    "    length = len(df)\n",
    "    ratio_fog = len(df.loc[df['prediction']<=1.0])/length\n",
    "    ratio_mist = len(df.loc[(df['prediction']>1.0) & (df['prediction']<=2.0)])/length\n",
    "    ratio_clear = len(df.loc[df['prediction']>2.0])/length\n",
    "    print(f'比例: 雾:{ratio_fog}, 轻雾{ratio_mist}, 无雾{ratio_clear}')\n",
    "    return (ratio_fog, ratio_mist, ratio_clear)\n",
    "\n",
    "def get_fog_TSscore(df, threshold=1.0):\n",
    "    length = len(df)\n",
    "    NA = len(df.loc[(df['prediction']<=threshold) & (df['y']<=threshold)]) # 正确数\n",
    "    NB = len(df.loc[(df['prediction']<=threshold) & (df['y']>threshold)]) # 空报数\n",
    "    NC = len(df.loc[(df['prediction']>threshold) & (df['y']<=threshold)]) # 空报数\n",
    "    TS_score = NA/(NA + NB + NC)\n",
    "    return TS_score\n",
    "\n",
    "def get_NWP_score(df):\n",
    "    y = df['station_vis'].apply(linear_vis)\n",
    "    y_p = df['visi'].apply(linear_vis)\n",
    "    df_s = pd.DataFrame({'prediction':y_p, 'y':y})\n",
    "    df_s.dropna(inplace=True)\n",
    "    df_s_fog = df_s.loc[df_s['y']<=1.0]\n",
    "    df_s_mist = df_s.loc[(df_s['y']>1.0) & (df_s['y']<=2.0)]\n",
    "    df_s_clear = df_s.loc[df_s['y']>2.0]\n",
    "    print('* 实况为雾时:', end=' ')\n",
    "    getLevelRatio(df_s_fog)\n",
    "    # print('-------------')\n",
    "    print('* 实况为轻雾时:', end=' ')\n",
    "    # print('-------------')\n",
    "    getLevelRatio(df_s_mist)\n",
    "    print('* 实况为无雾时:', end=' ')\n",
    "    getLevelRatio(df_s_clear)\n",
    "    print('* TS评分:', end=' ')\n",
    "    TS_fog = get_fog_TSscore(df_s, threshold=1.0)\n",
    "    TS_fog_mist = get_fog_TSscore(df_s, threshold=2.0)\n",
    "    print(f'雾: {TS_fog}, 轻雾及雾: {TS_fog_mist}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/test', '/train', '/valid', '/valid_test']\n",
      "(469269, 17)\n",
      "(469269,)\n"
     ]
    }
   ],
   "source": [
    "fog_dataset_hdf = os.path.normpath(os.path.join(file_dir, './fog_dataset_hdf66_fc120h_v2.h5'))\n",
    "store_dataset = pd.HDFStore(fog_dataset_hdf, mode='r')\n",
    "print(store_dataset.keys())\n",
    "df_train = store_dataset.get('train')\n",
    "df_valid =store_dataset.get('valid')\n",
    "df_test = store_dataset.get('test')\n",
    "df_valid_test = store_dataset.get('valid_test')\n",
    "x_columns = ['t_td', 'td_sst','t_sst','v100', 'v10m', 'u100', 'u10m', 't2mm', 't2md', 'sstk','year_sin','year_cos', 'day_sin', 'day_cos','delta_theta','delta_theta_e','theta_e925']\n",
    "\n",
    "(train_x, train_y) = setDataset(df_train, x_columns)\n",
    "(valid_x, valid_y) = setDataset(df_valid, x_columns)\n",
    "(test_x,  test_y)  = setDataset(df_test, x_columns)\n",
    "(valid_test_x, valid_test_y) = setDataset(df_valid_test, x_columns)\n",
    "\n",
    "\n",
    "\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_x_scaled = scaler.fit_transform(train_x)\n",
    "test_x_scaled  = scaler.transform(test_x)\n",
    "valid_x_scaled = scaler.transform(valid_x)\n",
    "valid_test_x_scaled = scaler.transform(valid_test_x)\n",
    "\n",
    "\n",
    "keep_cols = ['t_td', 'td_sst','t_sst','year_sin','year_cos', 'day_sin', 'day_cos','delta_theta','delta_theta_e'] # 不需要标准化变量的参数\n",
    "\n",
    "for iColumn in keep_cols:\n",
    "    index = x_columns.index(iColumn)\n",
    "    train_x_scaled[:,index] = train_x[:,index]\n",
    "    valid_x_scaled[:,index] = valid_x[:,index]\n",
    "    test_x_scaled[:,index]  = test_x[:,index]\n",
    "    valid_test_x_scaled[:,index]  = valid_test_x[:,index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'copy': True, 'with_mean': True, 'with_std': True}\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "train_x_scaled_fit = scaler.fit(train_x)\n",
    "params_fit = train_x_scaled_fit.get_params()\n",
    "print(params_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.97833201  4.09911624  3.26444358  4.18354527  3.25615019  3.37824326\n",
      "  2.70599268  3.95002623  3.99820856  4.90342882  0.67624848  0.6251678\n",
      "  0.65930821  0.71423223  1.73999737  4.97796997 13.24905271]\n",
      "[ 2.58056535 -1.88579295  0.6947724  -0.18032674 -0.52429002 -4.54404442\n",
      " -3.5676635  22.93255603 20.35199067 22.23778363  0.08341111  0.38065181\n",
      " -0.15661821  0.17508784  3.33270731 -3.04193444 62.84389222]\n",
      "[  3.91379754  16.80275392  10.65659191  17.50205102  10.60251407\n",
      "  11.41252755   7.32239637  15.60270724  15.98567166  24.04361415\n",
      "   0.457312     0.39083478   0.43468731   0.51012767   3.02759086\n",
      "  24.78018501 175.53739782]\n"
     ]
    }
   ],
   "source": [
    "print(train_x_scaled_fit.scale_)\n",
    "print(train_x_scaled_fit.mean_)\n",
    "print(train_x_scaled_fit.var_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3.93348118,  16.78846518,  10.63718083,  17.5447646 ,\n",
       "        10.6329209 ,  11.4260922 ,   7.37477208,  15.79478667,\n",
       "        16.18586566,  24.2304648 ,   0.45451261,   0.39162083,\n",
       "         0.44019898,   0.51050683,   3.04352201,  24.63456871,\n",
       "       176.93568747])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.var(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (train-mean)/std\n",
    "\n",
    "# mean=train_data.mean(axis=0)\n",
    "# train_data-=mean\n",
    "# std=train_data.std(axis=0)\n",
    "# train_data/=std\n",
    "# test_data-=mean\n",
    "# test_data/=std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 60)                1080      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 488       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,577\n",
      "Trainable params: 1,577\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model = tf.keras.models.load_model(os.path.normpath(os.path.join(file_dir, './model_singletest_fog_dataset_hdf66_fc120h_v2')))\n",
    "\n",
    "# Check its architecture\n",
    "new_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2003256380558014\n",
      "0.24662281572818756\n"
     ]
    }
   ],
   "source": [
    "print(new_model.evaluate(test_x_scaled, test_y, verbose=0))\n",
    "print(new_model.evaluate(valid_test_x_scaled, valid_test_y, verbose=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tf2.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a7deed390a820e4d192e7640652106b775a89fcd313a94c88690349b2d36e3c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
